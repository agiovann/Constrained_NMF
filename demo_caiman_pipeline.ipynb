{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a Calcium Imaging Video. </span></p>\n",
    "<p><img src=\"dev/kalfon/img/quickintro.png\" /></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in CaImAn&rsquo;s documentation. </span></p>\n",
    "</body></html>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "1\n",
      "numba not found\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 21 15:53:15 2016\n",
    "\n",
    "@author: agiovann\n",
    "\"\"\"\n",
    "%matplotlib\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from builtins import zip\n",
    "from builtins import str\n",
    "from builtins import map\n",
    "from builtins import range\n",
    "from past.utils import old_div\n",
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(1)\n",
    "except:\n",
    "    print('Open CV is naturally single threaded')\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        print((1))\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    print('Not IPYTHON')\n",
    "    pass\n",
    "#%%\n",
    "import caiman as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pylab as pl\n",
    "import psutil\n",
    "import sys\n",
    "from ipyparallel import Client\n",
    "from skimage.external.tifffile import TiffFile\n",
    "import scipy\n",
    "#%%\n",
    "from caiman.motion_correction import tile_and_correct, motion_correction_piecewise\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.components_evaluation import evaluate_components \n",
    "from caiman.utils.visualization import plot_contours, view_patches_bar\n",
    "from caiman.base.rois import extract_binary_masks_blob\n",
    "from caiman.utils.utils import download_demo\n",
    "\n",
    "\n",
    "#%%\n",
    "#m = cm.load('example_movies/demoMovie.tif')\n",
    "#\n",
    "#cm.concatenate([m.resize(1,1,.2),m.resize(1,1,.2)],axis =1).play(fr =20, gain = 3.,magnification =3)\n",
    "#%% set parameters and create template by RIGID MOTION CORRECTION\n",
    "params_movie = {'fname': 'example_movies/demoSue2x.tif',\n",
    "                'niter_rig': 1,\n",
    "                'max_shifts': (6, 6),  # maximum allow rigid shift\n",
    "                'splits_rig': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_rig': None,\n",
    "                # intervals at which patches are laid out for motion correction\n",
    "                'strides': (48, 48),\n",
    "                # overlap between pathes (size of patch strides+overlaps)\n",
    "                'overlaps': (24, 24),\n",
    "                'splits_els': 56,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "                # if none all the splits are processed and the movie is saved\n",
    "                'num_splits_to_process_els': [28, None],\n",
    "                'upsample_factor_grid': 4,  # upsample factor to avoid smearing when merging patches\n",
    "                # maximum deviation allowed for patch with respect to rigid\n",
    "                # shift\n",
    "                'max_deviation_rigid': 3,\n",
    "                'p': 1,  # order of the autoregressive system\n",
    "                'merge_thresh': 0.8,  # merging threshold, max correlation allowed\n",
    "                'rf': 15,  # half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "                'stride_cnmf': 6,  # amounpl.it of overlap between the patches in pixels\n",
    "                'K': 4,  # number of components per patch\n",
    "                # if dendritic. In this case you need to set init_method to\n",
    "                # sparse_nmf\n",
    "                'is_dendrites': False,\n",
    "                'init_method': 'greedy_roi',\n",
    "                'gSig': [4, 4],  # expected half size of neurons\n",
    "                'alpha_snmf': None,  # this controls sparsity\n",
    "                'final_frate': 30\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% parameters from dictionary\n",
    "fname = params_movie['fname']\n",
    "niter_rig = params_movie['niter_rig']\n",
    "# maximum allow rigid shift\n",
    "max_shifts = params_movie['max_shifts']  \n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_rig = params_movie['splits_rig']  \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_rig = params_movie['num_splits_to_process_rig']\n",
    "# intervals at which patches are laid out for motion correction\n",
    "strides = params_movie['strides']\n",
    "# overlap between pathes (size of patch strides+overlaps)\n",
    "overlaps = params_movie['overlaps']\n",
    "# for parallelization split the movies in  num_splits chuncks across time\n",
    "splits_els = params_movie['splits_els'] \n",
    "# if none all the splits are processed and the movie is saved\n",
    "num_splits_to_process_els = params_movie['num_splits_to_process_els']\n",
    "# upsample factor to avoid smearing when merging patches\n",
    "upsample_factor_grid = params_movie['upsample_factor_grid'] \n",
    "# maximum deviation allowed for patch with respect to rigid\n",
    "# shift\n",
    "max_deviation_rigid = params_movie['max_deviation_rigid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already existing\n"
     ]
    }
   ],
   "source": [
    "#%% download movie if not there\n",
    "if fname == 'example_movies/demoSue2x.tif':\n",
    "    download_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> we are now entering the process of rigid correction</h1>\n",
    "<p>wich will be based on the correlation to a template image. A correction will be find for each image as a displacement vector. this template image (usually the median of each image over time) will be updated each time that the movie is corrected to increase its precision </p>\n",
    "<img src=\"dev/kalfon/img/rigidcorrection.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping along z\n"
     ]
    }
   ],
   "source": [
    "#%% load movie (in memory!)\n",
    "m_orig = cm.load(fname)\n",
    "#%% play movie\n",
    "downsample_ratio = .2\n",
    "offset_mov = -np.min(m_orig[:100])\n",
    "m_orig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>some of the pixels in this movie are negative, we then need to make them positive </em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> As we can see here there is a parralelization process in the motioncorrect class </h2>\n",
    "<p> this class will do create temporal chunks of the movie for it to be treated in parallel on all the core of the computer. </p>\n",
    "<p> It uses ipyparrallel to parallelize the python ( see : https://ipyparallel.readthedocs.io/en/latest/intro.html) and slurm to manage the workload ( see : https://slurm.schedmd.com/quickstart.html ) </p>\n",
    "<p><img src=\"dev/kalfon/img/cordermmap.png\" /> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using 4 processes\n",
      "C was not existing, creating one\n",
      "Stopping  cluster to avoid unnencessary use of memory....\n",
      "Stopping cluster...\n",
      "NOT SLURM\n",
      "Waiting for cluster to stop.... done\n",
      "Starting cluster...Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-client.json\n",
      "....Using 4 processes\n",
      "Rigid Motion Correction\n",
      "296.0\n",
      "-296.0\n",
      "Frame 100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "caiman/base/movies.py:233: UserWarning: ** Pixels averages are too negative. Removing 1 percentile. **\n",
      "  warnings.warn('** Pixels averages are too negative. Removing 1 percentile. **')\n",
      "caiman/base/movies.py:251: UserWarning: Pixels averages are too negative for template. Removing 1 percentile.\n",
      "  warnings.warn('Pixels averages are too negative for template. Removing 1 percentile.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "cubic interpolation\n",
      "Frame 100\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "-296.0\n",
      "Frame 100\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "cubic interpolation\n",
      "Frame 100\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "-296.0\n",
      "Frame 100\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "cubic interpolation\n",
      "Frame 100\n",
      "Frame 200\n",
      "Frame 300\n",
      "Frame 400\n",
      "Frame 500\n",
      "Frame 600\n",
      "Adding to movie 296.0\n",
      "0\n",
      "saving!\n",
      "56.318420887\n",
      "0.038137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<caiman.motion_correction.MotionCorrect at 0x11c03e9d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% motion correction rigid\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "#%%\n",
    "# movie must be mostly positive for this to work\n",
    "min_mov = cm.load(fname, subindices=range(400)).min()\n",
    "\n",
    "mc = MotionCorrect(fname, min_mov,\n",
    "                   dview=dview, max_shifts=max_shifts, niter_rig=niter_rig, splits_rig=splits_rig, \n",
    "                   num_splits_to_process_rig=num_splits_to_process_rig, \n",
    "                strides= strides, overlaps= overlaps, splits_els=splits_els,\n",
    "                num_splits_to_process_els=num_splits_to_process_els, \n",
    "                upsample_factor_grid=upsample_factor_grid, max_deviation_rigid=max_deviation_rigid, \n",
    "      \n",
    "                shifts_opencv = True, nonneg_movie = True)\n",
    "#%%\n",
    "mc.motion_correct_rigid(save_movie=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmap\n"
     ]
    }
   ],
   "source": [
    "# load motion corrected movie\n",
    "m_rig = cm.load(mc.fname_tot_rig)\n",
    "pl.imshow(mc.total_template_rig, cmap = 'gray')\n",
    "#%% visualize templates\n",
    "cm.movie(np.array(mc.templates_rig)).play(\n",
    "    fr=10, gain=5, magnification=2, offset=offset_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11bc79c90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% plot rigid shifts\n",
    "pl.close()\n",
    "pl.plot(mc.shifts_rig)\n",
    "pl.legend(['x shifts','y shifts'])\n",
    "pl.xlabel('frames')\n",
    "pl.ylabel('pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping along z\n"
     ]
    }
   ],
   "source": [
    "#%% inspect movie\n",
    "bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)\n",
    "downsample_ratio = .2\n",
    "m_rig.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = offset_mov*.25, fr=30, magnification=2,bord_px = bord_px_rig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Piece-Wise rigid motion correction </h1>\n",
    "<p> used to do a non rigid motion correction in a fashion that has the same linear usage of computing power as a rigid motion correction <p>\n",
    "<img src=\"dev\\kalfon\\img\\pwrigidcorrection.png\" />\n",
    "<p> more info : </p>\n",
    "<em> http://biorxiv.org/content/biorxiv/early/2017/02/14/108514.full.pdf </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding to movie 296.0\n",
      "0\n",
      "saving mmap of example_movies/demoSue2x.tif\n",
      "**** MOVIE NOT SAVED BECAUSE num_splits is not None ****\n",
      "98.3150858879\n",
      "Adding to movie 296.0\n",
      "0\n",
      "saving mmap of example_movies/demoSue2x.tif\n",
      "209.301836014\n",
      "mmap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11c197690>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%% motion correct piecewise rigid\n",
    "mc.motion_correct_pwrigid(save_movie=True, template=mc.total_template_rig, show_template = True)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "pl.imshow(mc.total_template_els, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% visualize elastic shifts\n",
    "pl.close()\n",
    "pl.subplot(2, 1, 1)\n",
    "pl.plot(mc.x_shifts_els)\n",
    "pl.ylabel('x shifts (pixels)')\n",
    "pl.subplot(2, 1, 2)\n",
    "pl.plot(mc.y_shifts_els)\n",
    "pl.ylabel('y_shifts (pixels)')\n",
    "pl.xlabel('frames')\n",
    "#%% compute borders to exclude\n",
    "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                 np.max(np.abs(mc.y_shifts_els)))).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshaping along z\n",
      "reshaping along z\n",
      "reshaping along z\n",
      "reshaping along z\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1330d95d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check movie\n",
    "downsample_ratio = .2\n",
    "m_els.resize(1, 1, downsample_ratio).play(\n",
    "    gain=10, offset = 0, fr=30, magnification=2,bord_px = bord_px_els)\n",
    "# compare with original and rigid corrected movies\n",
    "downsample_factor = .2\n",
    "cm.concatenate([m_orig.resize(1, 1, downsample_factor)+offset_mov, m_rig.resize(1, 1, downsample_factor), m_els.resize(\n",
    "    1, 1, downsample_factor)], axis=2).play(fr=60, gain=15, magnification=2, offset=0)\n",
    "#%% local correlation\n",
    "pl.imshow(m_els.local_correlations(eight_neighbours=True, swap_dim=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Assessing Motion correction Quality </h1>\n",
    "for the raw, rigid corrected and piecewise rigid corrected videos\n",
    "<p> using smoothness <em> (mean over time) </em> </p>\n",
    "--------------\n",
    "<p> using correlation to the template <em> (Pearson Correlation coefficient)</em> </p> \n",
    "--------------\n",
    "see : http://docs.opencv.org/2.4/doc/tutorials/imgproc/histograms/template_matching/template_matching.html ( like a normalized SSD )\n",
    "<p> optical flow : </p>\n",
    "--------------\n",
    "<img src=\"dev/kalfon/img/opticalflow.png\" />\n",
    "more info :<em> http://docs.opencv.org/trunk/d7/d8b/tutorial_py_lucas_kanade.html </em>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mmap\n",
      "[5, -5, 5, -5]\n",
      "Local correlations..\n",
      "(3000, 160, 160)\n",
      "Compute Smoothness.. \n",
      "Compute correlations.. \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "Compute optical flow .. \n",
      "reshaping along z\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "mmap\n",
      "[5, -5, 5, -5]\n",
      "Local correlations..\n",
      "(3000, 160, 160)\n",
      "Compute Smoothness.. \n",
      "Compute correlations.. \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "Compute optical flow .. \n",
      "reshaping along z\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "[5, -5, 5, -5]\n",
      "Local correlations..\n",
      "(3000, 160, 160)\n",
      "Compute Smoothness.. \n",
      "Compute correlations.. \n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "Compute optical flow .. \n",
      "reshaping along z\n",
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "#% compute metrics for the results (TAKES TIME!!)\n",
    "final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px_els)\n",
    "winsize = 100\n",
    "swap_dim = False\n",
    "resize_fact_flow = .2\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_els, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    mc.fname_tot_rig, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)\n",
    "tmpl, correlations, flows_orig, norms, smoothness = cm.motion_correction.compute_metrics_motion_correction(\n",
    "    fname, final_size[0], final_size[1], swap_dim, winsize=winsize, play_flow=False, resize_fact_flow=resize_fact_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tmpl', 'smoothness_corr', 'img_corr', 'correlations', 'flows', 'norms', 'smoothness']\n",
      "example_movies/demoSue2x_els__d1_170_d2_170_d3_1_order_F_frames_3000_._metrics.npz\n",
      "11.4916+/-4.8676 ; 2811.64624023 ; 4.9987140926\n",
      "mmap\n",
      "['tmpl', 'smoothness_corr', 'img_corr', 'correlations', 'flows', 'norms', 'smoothness']\n",
      "example_movies/demoSue2x_rig__d1_170_d2_170_d3_1_order_F_frames_3000_._metrics.npz\n",
      "22.6324+/-14.5289 ; 2731.03808594 ; 5.07352105901\n",
      "mmap\n",
      "['tmpl', 'smoothness_corr', 'img_corr', 'correlations', 'flows', 'norms', 'smoothness']\n",
      "example_movies/demoSue2x_metrics.npz\n",
      "141.982+/-123.951 ; 1918.01208496 ; 5.743336641\n",
      "File is:\n",
      "example_movies/demoSue2xmmap\n"
     ]
    }
   ],
   "source": [
    "#%% plot the results of metrics\n",
    "fls = [mc.fname_tot_els[:-4] + '_metrics.npz', mc.fname_tot_rig[:-4] +\n",
    "       '_metrics.npz', mc.fname[:-4] + '_metrics.npz']\n",
    "#%%\n",
    "for cnt, fl, metr in zip(range(len(fls)),fls,['pw_rigid','rigid','raw']):\n",
    "    with np.load(fl) as ld:\n",
    "        print(ld.keys())\n",
    "#        pl.figure()\n",
    "        print(fl)\n",
    "        print(str(np.mean(ld['norms'])) + '+/-' + str(np.std(ld['norms'])) +\n",
    "              ' ; ' + str(ld['smoothness']) + ' ; ' + str(ld['smoothness_corr']))\n",
    "        \n",
    "        pl.subplot(len(fls), 4, 1 + 4 * cnt)\n",
    "        pl.ylabel(metr)\n",
    "        try:\n",
    "            mean_img = np.mean(\n",
    "            cm.load(fl[:-12] + 'mmap'), 0)[12:-12, 12:-12]\n",
    "        except:\n",
    "            try:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + '.tif'), 0)[12:-12, 12:-12]\n",
    "            except:\n",
    "                mean_img = np.mean(\n",
    "                    cm.load(fl[:-12] + 'hdf5'), 0)[12:-12, 12:-12]\n",
    "                    \n",
    "        lq, hq = np.nanpercentile(mean_img, [.5, 99.5])\n",
    "        pl.imshow(mean_img, vmin=lq, vmax=hq)\n",
    "        pl.title('Mean')\n",
    "        #        pl.plot(ld['correlations'])\n",
    "\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 2)\n",
    "        pl.imshow(ld['img_corr'], vmin=0, vmax=.35)\n",
    "        pl.title('Corr image')\n",
    "    #        pl.colorbar()\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 3)\n",
    "    #\n",
    "        pl.plot(ld['norms'])\n",
    "        pl.xlabel('frame')\n",
    "        pl.ylabel('norm opt flow')\n",
    "        pl.subplot(len(fls), 4, 4 * cnt + 4)\n",
    "        flows = ld['flows']\n",
    "        pl.imshow(np.mean(\n",
    "        np.sqrt(flows[:, :, :, 0]**2 + flows[:, :, :, 1]**2), 0), vmin=0, vmax=0.3)\n",
    "        pl.colorbar()\n",
    "        pl.title('Mean optical flow')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Memory mapping </h1>\n",
    "<p>needed to have a much faster and parallel computation of subset of the movie. creating spatial chunks of the movie to compute in parallel over time threw this chunks. accessing in memory chains of the same pixels through time.</p>\n",
    "<p><img src=\"dev/kalfon/img/fordermmap.png\" /></p>\n",
    "<h3> As you can see, there is already chunks of the movie but in the temporal order for the previous paralellization.</h3>\n",
    "<p> we are getting subchunks of the movie in the F order ( see https://en.wikipedia.org/wiki/Row-_and_column-major_order ) those subchunks are then glued together in the temporal axis ( F order ) to create spatial chunks of the entire movie that will get treated by the CNMF )\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['example_movies/demoSue2x0000_d1_170_d2_170_d3_1_order_C_frames_3000_.mmap']\n",
      "One file only, not saving!\n"
     ]
    }
   ],
   "source": [
    "# MEMORY MAPPING: save each chunk in F format on memory mapped files\n",
    "t1 = time.time()\n",
    "if not params_movie.has_key('max_shifts'):\n",
    "    fnames = [params_movie['fname']]\n",
    "    border_to_0 = 0\n",
    "elif not params_movie.has_key('overlaps'):\n",
    "    fnames = [mc.fname_tot_rig]\n",
    "    border_to_0 = bord_px_rig\n",
    "    m_els = m_rig\n",
    "else:\n",
    "    fnames = [mc.fname_tot_els]\n",
    "    border_to_0 = bord_px_els\n",
    "    \n",
    "# if you need to crop the borders use slicing    \n",
    "# idx_x=slice(border_nan,-border_nan,None)\n",
    "# idx_y=slice(border_nan,-border_nan,None)\n",
    "# idx_xy=(idx_x,idx_y)\n",
    "idx_xy = None\n",
    "add_to_movie = -np.nanmin(m_els) + 1  # movie must be positive\n",
    "# if you need to remove frames from the beginning of each file\n",
    "remove_init = 0\n",
    "# downsample movie in time: use .2 or .1 if file is large and you want a quick answer             \n",
    "downsample_factor = 1 \n",
    "base_name = fname.split('/')[-1][:-4]\n",
    "name_new = cm.save_memmap_each(fnames, dview=dview, base_name=base_name, resize_fact=(\n",
    "    1, 1, downsample_factor), remove_init=remove_init, idx_xy=idx_xy, add_to_movie=add_to_movie, border_to_0=border_to_0)\n",
    "name_new.sort()\n",
    "print(name_new)\n",
    "\n",
    "#%% concatenate chunks if needed\n",
    "if len(name_new) > 1:\n",
    "    fname_new = cm.save_memmap_join(\n",
    "        name_new, base_name='Yr', n_chunks=12, dview=dview)\n",
    "else:\n",
    "    print('One file only, not saving!')\n",
    "    fname_new = name_new[0]\n",
    "\n",
    "t2 = time.time() - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremie/anaconda2/envs/CaImAn/lib/python2.7/site-packages/past/utils/__init__.py:95: RuntimeWarning: invalid value encountered in divide\n",
      "  return a / b\n"
     ]
    }
   ],
   "source": [
    "#%% LOAD MEMMAP FILE\n",
    "# fname_new='Yr_d1_501_d2_398_d3_1_order_F_frames_369_.mmap'\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "d1, d2 = dims\n",
    "images = np.reshape(Yr.T, [T] + list(dims), order='F')\n",
    "Y = np.reshape(Yr, dims + (T,), order='F')\n",
    "m_images = cm.movie(images)\n",
    "#%%  checks on movies (might take time if large!)\n",
    "if np.min(images) < 0:\n",
    "    raise Exception('Movie too negative, add_to_movie should be larger')\n",
    "if np.sum(np.isnan(images)) > 0:\n",
    "    raise Exception('Movie contains nan! You did not remove enough borders')\n",
    "#%% correlation image\n",
    "Cn = cm.local_correlations(Y)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "pl.imshow(Cn, cmap='gray', vmax=.35)\n",
    "#%% some parameter settings\n",
    "# order of the autoregressive fit to calcium imaging in general one (slow gcamps) or two (fast gcamps fast scanning)\n",
    "p = params_movie['p']  \n",
    "# merging threshold, max correlation allowed\n",
    "merge_thresh= params_movie['merge_thresh'] \n",
    "# half-size of the patches in pixels. rf=25, patches are 50x50\n",
    "rf = params_movie['rf']  \n",
    "# amounpl.it of overlap between the patches in pixels\n",
    "stride_cnmf = params_movie['stride_cnmf'] \n",
    " # number of components per patch\n",
    "K =  params_movie['K'] \n",
    "# if dendritic. In this case you need to set init_method to sparse_nmf\n",
    "is_dendrites = params_movie['is_dendrites']\n",
    "# iinit method can be greedy_roi for round shapes or sparse_nmf for denritic data\n",
    "init_method = params_movie['init_method']\n",
    "# expected half size of neurons\n",
    "gSig = params_movie['gSig']  \n",
    "# this controls sparsity\n",
    "alpha_snmf = params_movie['alpha_snmf']  \n",
    "#frame rate of movie (even considering eventual downsampling)\n",
    "final_frate = params_movie['final_frate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CNMF on patches </h1>\n",
    "<p> where we will Extract spatial and temporal components on patches </p>\n",
    "\n",
    "More information here : <em> http://www.cell.com/neuron/fulltext/S0896-6273(15)01084-3?_returnURL=http%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS0896627315010843%3Fshowall%3Dtrue </em>\n",
    "\n",
    "<p> <img src=\"dev/kalfon/img/cnmf1.png\" /> </p>\n",
    "\n",
    "<p> A merging step is added to merge all the same neurons that have been identified by different cnmf on different chunks <p>\n",
    "<em> this is done by comparing the temporal activity of neurons which have more than a certain amount of shared space </em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 170, 170)\n",
      "using 4 processes\n",
      "using 4000 pixels per process\n",
      "using 20000 block_size\n",
      "*\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 31)\n",
      "(31, 30)\n",
      "(30, 31)\n",
      "(30, 31)\n",
      "(30, 31)\n",
      "(30, 31)\n",
      "(30, 31)\n",
      "(30, 31)\n",
      "(30, 30)\n",
      "You may think that it went well but reality is harsh\n",
      "11.3403260708\n",
      "Transforming patches into full matrix\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Done!\n",
      "Generating background\n",
      "using 4 processes\n",
      "using 4000 pixels per process\n",
      "using 20000 block_size\n",
      "merging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremie/anaconda2/envs/CaImAn/lib/python2.7/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csc_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44 48 72 76]\n",
      "[140 145 168 172]\n",
      "[ 78 100 104]\n",
      "[12 19 40]\n",
      "[153 157 181]\n",
      "[ 1 29]\n",
      "[28 32]\n",
      "[20 24]\n",
      "[88 92]\n",
      "[49 53]\n",
      "[132 160]\n",
      "[156 184]\n",
      "[114 116]\n",
      "[ 73 102]\n",
      "[23 26]\n",
      "[113 141]\n",
      "[ 9 36]\n",
      "[11 37]\n",
      "[107 108]\n",
      "[85 89]\n",
      "[142 170]\n",
      "[74 77]\n",
      "[148 176]\n",
      "[61 91]\n",
      "[121 125]\n",
      "[70 75]\n",
      "[166 194]\n",
      "[175 179]\n",
      "[186 188]\n",
      "[159 161]\n",
      "[189 192]\n",
      "[135 136]\n",
      "done merging\n",
      "********** No neurons merged! ***************\n",
      "done merging\n",
      "update temporal\n",
      "Generating residuals\n",
      "Forcing single thread for memory issues\n",
      "parallel dot product block size: 20000\n",
      "Start product\n",
      "Transposing\n",
      "19999\n",
      "28899\n",
      "Done\n",
      "0\n",
      "100\n",
      "52 out of total 157 temporal components updated\n",
      "101 out of total 157 temporal components updated\n",
      "137 out of total 157 temporal components updated\n",
      "154 out of total 157 temporal components updated\n",
      "157 out of total 157 temporal components updated\n",
      "52 out of total 157 temporal components updated\n",
      "101 out of total 157 temporal components updated\n",
      "137 out of total 157 temporal components updated\n",
      "154 out of total 157 temporal components updated\n",
      "157 out of total 157 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Number of components:157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "caiman/utils/visualization.py:852: UserWarning: The way to call utilities.plot_contours has changed. Look at the definition for more details.\n",
      "  warn(\"The way to call utilities.plot_contours has changed. Look at the definition for more details.\")\n"
     ]
    }
   ],
   "source": [
    "if params_movie['is_dendrites'] == True:\n",
    "    if params_movie['init_method'] is not 'sparse_nmf':\n",
    "        raise Exception('dendritic requires sparse_nmf')\n",
    "    if params_movie['alpha_snmf'] is None:\n",
    "        raise Exception('need to set a value for alpha_snmf')\n",
    "#%% Extract spatial and temporal components on patches\n",
    "t1 = time.time()\n",
    "cnm = cnmf.CNMF(n_processes, k=K, gSig=gSig, merge_thresh=0.8, p=0, dview=dview, Ain=None, rf=rf, stride=stride_cnmf, memory_fact=1,\n",
    "                method_init=init_method, alpha_snmf=alpha_snmf, only_init_patch=True, gnb=1, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "\n",
    "A_tot = cnm.A\n",
    "C_tot = cnm.C\n",
    "YrA_tot = cnm.YrA\n",
    "b_tot = cnm.b\n",
    "f_tot = cnm.f\n",
    "sn_tot = cnm.sn\n",
    "t2 = time.time() - t1\n",
    "print(('Number of components:' + str(A_tot.shape[-1])))\n",
    "#%%\n",
    "pl.figure()\n",
    "crd = plot_contours(A_tot, Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>DISCARD LOW QUALITY COMPONENT </h1>\n",
    "<p> important step because too many neurons have being sleected and are false. </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing event exceptionality delta\n",
      "Removing Baseline\n",
      "Computing event exceptionality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "caiman/components_evaluation.py:119: RuntimeWarning: divide by zero encountered in log\n",
      "  erf = np.log(erf)\n",
      "/Users/jeremie/anaconda2/envs/CaImAn/lib/python2.7/site-packages/numpy/core/fromnumeric.py:2889: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating spatial footprint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremie/anaconda2/envs/CaImAn/lib/python2.7/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n",
      "caiman/components_evaluation.py:289: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  idx_components_r = np.where(r_values >= r_values_min)[0]  # threshold on space consistency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping 75 and discarding  82\n"
     ]
    }
   ],
   "source": [
    "#%% DISCARD LOW QUALITY COMPONENT\n",
    "from caiman.components_evaluation import estimate_components_quality\n",
    "t1 = time.time()\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .7  # threshold on space consistency\n",
    "fitness_min = -40  # threshold on time variability\n",
    "# threshold on time variability (if nonsparse activity)\n",
    "fitness_delta_min = -40\n",
    "Npeaks = 10\n",
    "traces = C_tot + YrA_tot\n",
    "idx_components, idx_components_bad = estimate_components_quality(\n",
    "    traces, Y, A_tot, C_tot, b_tot, f_tot, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "t2 = time.time() - t1\n",
    "print(('Keeping ' + str(len(idx_components)) +\n",
    "       ' and discarding  ' + str(len(idx_components_bad))))\n",
    "#%%\n",
    "pl.figure()\n",
    "crd = plot_contours(A_tot.tocsc()[:, idx_components], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> CNMF full frame </h1> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 170, 170)\n",
      "using 4 processes\n",
      "using 4000 pixels per process\n",
      "using 20000 block_size\n",
      "preprocessing ...\n",
      "checking if missing data\n",
      "Running on 4 engines.\n",
      "update spatial ...\n",
      "found spatial support for each component\n",
      "(28900, 75)\n",
      "Starting Update Spatial Components\n",
      "Updated Spatial Components\n",
      "threshold\n",
      "Computing residuals\n",
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Filling\n",
      "Computing A_bas\n",
      "--- 12.9369649887 seconds ---\n",
      "Remove temporary file created\n",
      "update temporal ...\n",
      "Generating residuals\n",
      "Forcing single thread for memory issues\n",
      "parallel dot product block size: 20000\n",
      "Start product\n",
      "Transposing\n",
      "19999\n",
      "28899\n",
      "Done\n",
      "0\n",
      "41 out of total 75 temporal components updated\n",
      "66 out of total 75 temporal components updated\n",
      "74 out of total 75 temporal components updated\n",
      "75 out of total 75 temporal components updated\n",
      "41 out of total 75 temporal components updated\n",
      "66 out of total 75 temporal components updated\n",
      "74 out of total 75 temporal components updated\n",
      "75 out of total 75 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "merge components ...\n",
      "********** No neurons merged! ***************\n",
      "done merging\n",
      "(28900, 75)\n",
      "update spatial ...\n",
      "found spatial support for each component\n",
      "(28900, 75)\n",
      "Starting Update Spatial Components\n",
      "Updated Spatial Components\n",
      "threshold\n",
      "Computing residuals\n",
      "parallel dot product block size: 1000\n",
      "Start product\n",
      "Filling\n",
      "Computing A_bas\n",
      "--- 9.69385099411 seconds ---\n",
      "Remove temporary file created\n",
      "update temporal ...\n",
      "Generating residuals\n",
      "Forcing single thread for memory issues\n",
      "parallel dot product block size: 20000\n",
      "Start product\n",
      "Transposing\n",
      "19999\n",
      "28899\n",
      "Done\n",
      "0\n",
      "41 out of total 75 temporal components updated\n",
      "65 out of total 75 temporal components updated\n",
      "73 out of total 75 temporal components updated\n",
      "75 out of total 75 temporal components updated\n",
      "41 out of total 75 temporal components updated\n",
      "65 out of total 75 temporal components updated\n",
      "73 out of total 75 temporal components updated\n",
      "75 out of total 75 temporal components updated\n",
      "stopping: overall temporal component not changing significantly\n",
      "Computing event exceptionality delta\n",
      "Removing Baseline\n",
      "Computing event exceptionality\n",
      "Evaluating spatial footprint\n",
      " ***** \n",
      "75\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "A_tot = A_tot.tocsc()[:, idx_components]\n",
    "C_tot = C_tot[idx_components]\n",
    "#%% rerun updating the components to refine\n",
    "cnm = cnmf.CNMF(n_processes, k=A_tot.shape, gSig=gSig, merge_thresh=merge_thresh, p=p, dview=dview, Ain=A_tot, Cin=C_tot,\n",
    "                f_in=f_tot, rf=None, stride=None, method_deconvolution='oasis')\n",
    "cnm = cnm.fit(images)\n",
    "#%%\n",
    "A, C, b, f, YrA, sn = cnm.A, cnm.C, cnm.b, cnm.f, cnm.YrA, cnm.sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Discard low quality components on full frame</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% again recheck quality of components, stricter criteria\n",
    "final_frate = params_movie['final_frate']\n",
    "r_values_min = .75\n",
    "fitness_min = - 50\n",
    "fitness_delta_min = - 50\n",
    "Npeaks = 10\n",
    "traces = C + YrA\n",
    "idx_components, idx_components_bad = estimate_components_quality(\n",
    "    traces, Y, A, C, b, f, final_frate=final_frate, Npeaks=Npeaks, r_values_min=r_values_min, fitness_min=fitness_min, fitness_delta_min=fitness_delta_min)\n",
    "print(' ***** ')\n",
    "print((len(traces)))\n",
    "print((len(idx_components)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% visualize included and excluded components\n",
    "pl.subplot(1, 2, 1)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components], Cn, thr=0.9)\n",
    "pl.subplot(1, 2, 2)\n",
    "crd = plot_contours(A.tocsc()[:, idx_components_bad], Cn, thr=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component:0\n",
      "Component:0\n",
      "Component:1\n",
      "Component:2\n",
      "Component:3\n",
      "Component:4\n",
      "Component:5\n",
      "Component:4\n",
      "Component:3\n",
      "Component:2\n",
      "Component:1\n",
      "Component:0\n",
      "Component:2\n",
      "Component:2\n",
      "Component:3\n",
      "Component:4\n",
      "Component:5\n",
      "Component:6\n",
      "Component:7\n",
      "Component:8\n",
      "Component:8\n",
      "Component:8\n",
      "Component:8\n",
      "Component:7\n",
      "Component:6\n",
      "Component:5\n",
      "Component:4\n",
      "Component:3\n",
      "Component:2\n",
      "Component:1\n",
      "Component:0\n",
      "Component:0\n",
      "Component:1\n",
      "Component:1\n",
      "Component:2\n",
      "Component:3\n",
      "Component:4\n",
      "Component:5\n",
      "Component:6\n",
      "Component:7\n",
      "Component:8\n",
      "Component:9\n",
      "Component:10\n",
      "Component:11\n",
      "Component:12\n",
      "Component:13\n",
      "Component:14\n",
      "Component:15\n",
      "Component:16\n",
      "Component:17\n"
     ]
    }
   ],
   "source": [
    "#%% visualize spatial and temporal components\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components]), C[\n",
    "    idx_components, :], b, f, dims[0], dims[1], YrA=YrA[idx_components, :], img=Cn)\n",
    "#%%\n",
    "view_patches_bar(Yr, scipy.sparse.coo_matrix(A.tocsc()[:, idx_components_bad]), C[\n",
    "    idx_components_bad, :], b, f, dims[0], dims[1], YrA=YrA[idx_components_bad, :], img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> closing, saving, and creating denoised version </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% save results\n",
    "np.savez(os.path.join(os.path.split(fname_new)[0], os.path.split(fname_new)[1][:-4] + 'results_analysis.npz'), Cn=Cn, A=A.todense(\n",
    "), C=C, b=b, f=f, YrA=YrA, sn=sn, d1=d1, d2=d2, idx_components=idx_components, idx_components_bad=idx_components_bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping cluster...\n",
      "NOT SLURM\n",
      "Waiting for cluster to stop....... done\n"
     ]
    }
   ],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server()\n",
    "log_files = glob.glob('Yr*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(A.dot(C) + b.dot(f)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%% \n",
    "denoised.play(gain = 10, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie without background\n",
    "denoised = cm.movie(A.dot(C)).reshape(dims+(-1,),order = 'F').transpose([2,0,1])\n",
    "#%%\n",
    "denoised.play(gain = 30, offset = 0,fr =100, magnification = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
